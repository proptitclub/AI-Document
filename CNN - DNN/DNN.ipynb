{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1teTahX8Exe1sAoa7yYvbdJGWzlF2e1IZ",
      "authorship_tag": "ABX9TyMiHsDtEu6bWenv6X3LRYOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoaileba/AI/blob/master/DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvEZbjl0CfY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtCv_rNaZ8NS",
        "colab_type": "text"
      },
      "source": [
        "I) DEEP LEARNING:\n",
        "  - Là 1 mảng của Machine learning\n",
        "  - có thể đạt được sức mạnh lớn và linh hoạt trong việc nhận diện thông qua cách học thể hiện thế giới qua 1 hệ thống phân cấp các khái niệm, những khái niệm phức tạp có thể được xác định thông qua các khái niệm ít phức tạp hơn VD như mặt con người được định nghĩa thông qua các bộ phận như mắt mũi miệng, sau đó là cách bố trí của các bộ phận ấy thông qua đó định nghĩa như thế nào là mặt người\n",
        "  - nói cách khác thì Deep Learning sẽ học từng bước dần dần đi từ các đặc tính với mức độ thấp sau đó cao dần lên. Điều này thông qua các hidden layer của 1 Neural Network với mỗi node trong hidden layer biểu diễn 1 khía cạnh nào đó của chủ thể và cùng với các node khác nó biểu diễn hoàn thiện 1 chủ thể.\n",
        "  \n",
        "  ![alt text](https://miro.medium.com/max/1344/1*KYUUg9JC6InYe-VNPMDzAA.png)\n",
        "\n",
        "  - Khác với các thuật toán Machine learning truyền thống khác thì Deep learning sẽ cho ra kết quả tốt hơn với dữ liệu ngày càng được cung cấp nhiều hơn. Cái thứ 2 khác so với Machine Learning khi ta phải phải phân tích dữ liệu ra trước khi dung thuật toán VD như ảnh thì phải phân tích ra các đặc trưng của anh trước nó là gì sau đó mới dùng dữ liệu đã được phân tích cho vào các thuật toán ML, còn đối với Deep Learning do nó sẽ tự phân tích và tự học theo mức độ đặc tính từ thấp đên cao qua đó nhận diện được ảnh\n",
        "\n",
        "  ![alt text](https://miro.medium.com/max/1386/1*ZX05x1xYgaVoa4Vn2kKS9g.png)\n",
        "\n",
        "II) KHI NÀO DÙNG DEEP LEARNING:\n",
        " - Khi dữ liệu lớn thì nên sử dụng Deep Learning.\n",
        " - Cần phải giải quyết các bài toán phức tạp như các bài toán nhận diện\n",
        " \n",
        "III) 1 SỐ MÔ HÌNH DEEP LEARNING PHỔ BIẾN :\n",
        "  - DNN (DEEP NEURAL NETWORK)\n",
        "  - CNN (CONVOLUTIONAL NEURAL NETWORK)\n",
        "  - LTSM ( Long Short Term Memory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPlcNA3RyeC2",
        "colab_type": "text"
      },
      "source": [
        "# DEEP NEURAL NETWORK\n",
        "\n",
        "- Đây là 1 mạng Neural Network mô phỏng lại các neuron thần kinh của con người với mỗi node trong mạng là 1 tế bào neuron nhằm mô phỏng cách nhận biết 1 thực thể thông qua các phép tính với weight, bias và các node.\n",
        "- Deep neural network là 1 mạng NN trong đó nó có nhiều lớp hidden và mối hidden layer chứa hàng trăm , hàng nghìn các node qua đó có thể giải quyết các bài toán phức tạp như \n",
        "\n",
        "![alt text](https://nordiccoder.com/app/uploads/2019/10/Screen-Shot-2019-10-17-at-3.31.58-PM.png)\n",
        "\n",
        "Vậy Deep Neural Network hoạt động như thế nào ?\n",
        "\n",
        "I) HOẠT ĐỘNG:\n",
        "\n",
        "1) Feedforward:\n",
        "- lấy ví dụ đơn giản với mo hình sau :\n",
        "\n",
        "  ![alt text](https://i2.wp.com/nttuan8.com/wp-content/uploads/2019/03/sigmoid-1.png?resize=768%2C326&ssl=1)\n",
        "\n",
        "  ta có input đầu vào là 1 vector đó là X = $[1,x1,x2]$ và 1 output.\n",
        "  ở đây mới mỗi node input đến với output ta có được các trọng số weight (W) từ đó ta tính được giá trị của z của output là : \n",
        "\n",
        "  z = W*X \n",
        "\n",
        "  sau khi tính toán xong ta sẽ cho z vào 1 hàm non-linear để tìm ra được giá trị của node output đó là Yhat.\n",
        "\n",
        "  Nếu như thay vì node ta vừa tính là node output mà là node của hidden layer thì ta cũng sẽ phải làm tương tự và từ đó mở rộng lên ta có các tính toán cho DNN đó là từ input ta tính toán dựa vào giá trị các node input và các trọng số W và hệ số tự do bias để tính toán cho ra hidden layer 1, quá trình đó lại lặp lại để tính ra hidden layer 2..... đên khi gặp được output layer thì dừng \n",
        "\n",
        "  ![alt text](https://i2.wp.com/nttuan8.com/wp-content/uploads/2019/03/nn_full-2.png?resize=578%2C377&ssl=1)\n",
        "\n",
        "Với ví dụ này dựa vào quy tắc trên ta tính toán được:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Quá trình này được gọi là FEEDFORWARD \n",
        "\n",
        "- Nhưng ở đây mới chỉ là đưaa dữ liệu vào tính toán thông thường và cho ra kết quả vậy DNN \"học\" ở chỗ nào ? \n",
        "     \n",
        "    Việc học của DNN đó chính là việc thông qua cách cập nhật, tinh chỉnh lại trọng số W và hệ số bias sao cho phù hợp để có thể ra được kết quả với độ sai lệch ít nhất so với kết quả thực tế, việc tinh chỉnh lại trọng số được dựa trên gradient decent và hàm mất mát của Model mà ta sử dụng Và Quá trình cập nhật lại các trọng số đó là Back-Propagation\n",
        "\n",
        "\n",
        "2) Back-propagation:\n",
        "\n",
        "Ngược với Feedforward là khi ta đẩy dữ liệu vào thông qua các phép toán các hàm để ra được output thì ở đây ta sẽ dựa vào output để tính toán ngược lại xem liệu ta có thể cải thiện độ chính xác của Model hay không .\n",
        "\n",
        "Đầu tiên hãy đánh giá output so với thực tế.\n",
        "\n",
        "Có bài toán dự đoán chữ số viết tay MNIST và ta phải phân loại nó ra làm 10 lớp ta sẽ dùng one-hot-coding để tạo ra dữ liệu đánh giá.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1Urp7HzbPcrEj6Cx16uSmQfoQlJxZeL_R)\n",
        "![picture](https://drive.google.com/uc?id=1ss9EAj9tjhuktEa3rHczQcbV7i0DSYPF)\n",
        "![picture](https://drive.google.com/uc?id=1t9eZRLC4PJGRarRHD_9tgxLcVhNYH0R0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZVzZyrMJxrB",
        "colab_type": "code",
        "outputId": "bc01936d-6657-4007-b93d-05422a11ccc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "# from tensorflow.examples\n",
        "# from tensorflow.keras.datasets.mnist import \n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) =load_data()\n",
        "Mnist = mnist.load_data()\n",
        "x = x_train/255.0\n",
        "y = to_categorical(y_train)\n",
        "# print(y)\n",
        "x_test = x_test/255.0\n",
        "# print(x[0])\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSWVne_tZ7BL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HesRLgj3Z6KJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZwBmK_fQolD",
        "colab_type": "code",
        "outputId": "9b84f058-609c-45b7-d84b-a85bb74b34f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def data_iter(batch_size, features, labels):\n",
        "  num_examples = len(features)\n",
        "  indices = list(range(num_examples))\n",
        "  random.shuffle(indices)\n",
        "  for i in range(0, num_examples, batch_size):\n",
        "    batch_indices = np.array(\n",
        "                        indices[i: min(i + batch_size, num_examples)])\n",
        "    yield features[batch_indices], labels[batch_indices]\n",
        "\n",
        "\n",
        "class DNN():\n",
        "  def __init__(self,Layers,alpha = 0.1):\n",
        "    self.Layers = Layers\n",
        "    self.alpha = alpha\n",
        "    params = {}\n",
        "    for id in  range(len(self.Layers)):\n",
        "      if id != len(Layers)-1:\n",
        "        print(self.Layers[id])\n",
        "        input_dim = Layers[id]['units']\n",
        "        output_dim = Layers[id+1]['units']\n",
        "        params['W'+str(id)] = np.random.randn(input_dim,output_dim)*0.1\n",
        "        params['b'+str(id)] = np.zeros((output_dim,1))\n",
        "    self.params = params\n",
        "    # print(seft.b)\n",
        "\n",
        "\n",
        "  def Relu(self,Z):\n",
        "    return np.maximum(0,Z)\n",
        "  def Relu_grad(self,Z):\n",
        "    X_ = np.ones_like(Z)\n",
        "    X_[Z<=0] = 0\n",
        "    return X_\n",
        "    \n",
        "\n",
        "  def softmax(self, Z):\n",
        "    Ev=np.exp(Z-np.max(Z,axis=1,keepdims=True))\n",
        "    return Ev / Ev.sum(axis=1, keepdims=True)\n",
        " \n",
        "    \n",
        "\n",
        "  def softmax_grad(self, Z):\n",
        "    return self.softmax(Z)*(1-self.softmax(Z))\n",
        "\n",
        "  def feedforward(self,X):\n",
        "\n",
        "    A = [X]\n",
        "    out = A[-1]\n",
        "    for i in range(0, len(self.Layers) - 1):\n",
        "      Z = np.dot(out,self.params['W'+str(i)]) + (self.params['b'+str(i)].T)\n",
        "      if(self.Layers[i]['activation'] is 'Relu'):\n",
        "        out = self.Relu(Z)\n",
        "        A.append(out)\n",
        "      else:\n",
        "        out = self.softmax(Z)\n",
        "        A.append(out)\n",
        "\n",
        "    return A\n",
        "\n",
        "\n",
        "  def Loss_func(self,Y,Yhat):\n",
        "    return -np.sum(Y*np.log(Yhat))*1/Y.shape[0]\n",
        "\n",
        "\n",
        "  def back_propagation(self,X,y,id):\n",
        "    \n",
        "    A = self.feedforward(X)\n",
        "    a  = A[-1]\n",
        "    y = np.array(y).reshape(-1,10)\n",
        "    dZ = [(A[-1]-y)*1/X.shape[0]]\n",
        "    dw = []\n",
        "    db = []\n",
        "\n",
        "    for i in reversed(range(0,len(self.Layers)-1)):\n",
        "      if(self.Layers[i]['activation'] is 'Relu'):\n",
        "        dw_ = np.dot(A[i].T,dZ[-1])\n",
        "        db_ = (np.sum(dZ[-1], 0)).reshape(-1,1)\n",
        "        dZ_ = np.dot(dZ[-1]*self.Relu_grad(A[i+1]),self.params['W'+str(i)].T)\n",
        "        dZ.append(dZ_)\n",
        "        db.append(db_)\n",
        "        dw.append(dw_)\n",
        "        # print(self.Relu_grad(A[i+1])[0])\n",
        "      else:\n",
        "        dw_ = np.dot(A[i].T,dZ[-1])\n",
        "        db_ = (np.sum(dZ[-1], 0)).reshape(-1,1)\n",
        "        dZ_ = np.dot(dZ[-1]*self.softmax_grad(A[i+1]),self.params['W'+str(i)].T)\n",
        "        dZ.append(dZ_)\n",
        "        db.append(db_)\n",
        "        dw.append(dw_)\n",
        "        # print(self.softmax(A[i+1])[0])\n",
        "\n",
        "    dw = dw[::-1]\n",
        "    db = db[::-1]\n",
        "\n",
        "    for i in range(0,len(self.Layers)-1):\n",
        "      self.params['W'+str(i)] = self.params['W'+str(i)] - self.alpha*dw[i]\n",
        "      self.params['b'+str(i)] = self.params['b'+str(i)] - self.alpha*db[i]\n",
        "    return self.Loss_func(y,a)\n",
        "\n",
        "\n",
        "  def fit(self,X,y,epochs,batch_size):\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      ac = []\n",
        "      lost =[]\n",
        "      for X_,y_ in data_iter(batch_size,X,y):\n",
        "        lost.append(self.back_propagation(X_,y_,epoch))\n",
        "        ac.append(self.predict(X_,y_))\n",
        "      \n",
        "      if epoch%1 == 0:\n",
        "        acc = np.array(ac).mean()\n",
        "        loss = np.array(lost).mean()\n",
        "        print(\"Epoch: {} - loss: {} - accuracy: {}\".format(epoch,loss,acc))\n",
        "\n",
        "\n",
        "  def predict(self,X,y):\n",
        "    label = self.feedforward(X)\n",
        "    l = np.argmax(label[-1],axis = 1)\n",
        "    ac = np.argmax(y,axis= 1)\n",
        "    accuracy = (l == ac).mean()\n",
        "    return accuracy\n",
        "\n",
        "Layers = [\n",
        "          {'units':784,'activation' : 'Relu'},#input \n",
        "          {'units':512,'activation' : 'Relu'},\n",
        "          {'units':512, 'activation' : 'Relu' },# hidden \n",
        "          {'units':512,'activation' : 'Relu'}, # hidden \n",
        "          {'units':256,'activation' : 'Softmax'},\n",
        "          {'units':10} # output \n",
        "          ]\n",
        "\n",
        "\n",
        "DNN = DNN(Layers)\n",
        "DNN.fit(x,y,10,80)\n",
        "print(DNN.predict(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'units': 784, 'activation': 'Relu'}\n",
            "{'units': 512, 'activation': 'Relu'}\n",
            "{'units': 512, 'activation': 'Relu'}\n",
            "{'units': 512, 'activation': 'Relu'}\n",
            "{'units': 256, 'activation': 'Softmax'}\n",
            "Epoch: 0 - loss: 0.48248643998858265 - accuracy: 0.9208666666666666\n",
            "Epoch: 1 - loss: 0.20025080593868955 - accuracy: 0.9712\n",
            "Epoch: 2 - loss: 0.14997052736497002 - accuracy: 0.9818\n",
            "Epoch: 3 - loss: 0.12133660038189464 - accuracy: 0.9876500000000001\n",
            "Epoch: 4 - loss: 0.1021447183211463 - accuracy: 0.9907833333333335\n",
            "Epoch: 5 - loss: 0.08914290069725087 - accuracy: 0.9932333333333333\n",
            "Epoch: 6 - loss: 0.07758119007866195 - accuracy: 0.9943833333333334\n",
            "Epoch: 7 - loss: 0.07020455628038613 - accuracy: 0.9960666666666667\n",
            "Epoch: 8 - loss: 0.06342827824808556 - accuracy: 0.99665\n",
            "Epoch: 9 - loss: 0.057465290769211926 - accuracy: 0.9976166666666668\n",
            "0.9617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylkNkbqigQHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ina7Po2nxrl",
        "colab_type": "text"
      },
      "source": [
        "# CONVOLUTIONAL NEURAL NETWORK\n",
        "\n",
        " Đây là 1 Loại mạng DNN nhưng ta sẽ sử dụng phép tính Tích Chập để phân tích lấy đặc trưng.\n",
        " \n",
        " Hiểu 1 cách đơn giản thì đây cũng là 1 Loại ANN hay 1 Multilayer Perceptron nhưng sẽ có thêm 1 vài lớp Layer phục vụ cho từng tác vụ (Convolution và Pooling)\n",
        "\n",
        "I) Convolutional Layer - Kernel:\n",
        "- Convolutional Layer là 1 hidden layer ở đó chúng ta sẽ dùng 1 ma trận làm cửa sổ trượt nhằm mục đích tính toán và tìm ra được các đặc tính(feature) và tạo ra 1 feature map với chiều xâu của ảnh tăng lên.\n",
        "\n",
        "![alt text](https://topdev.vn/blog/wp-content/uploads/2019/08/Convolution_schematic.gif)\n",
        "\n",
        "- Ma trận làm cửa sổ trượt đó chính là Kernel chứa các trọng số nó sẽ làm phép tính chập để từ đó lôi ra được đặc trưng của ảnh và feature map sau khi ra khỏi lớp Conv có kích thước phụ thuộc vào số lượng Filter, Padding và Stride\n",
        "\n",
        "- Padding: là cách mà chúng ta thêm những hang cột 0 vào ảnh ban đầu điều này có thể giúp chúng ta giữ nguyên kích thước của ảnh sau khi dùng tích chập và khi thêm đủ lượng hàng và cột 0 các chi tiết ở các góc và các mép ảnh sẽ được giữ lại nhiều hơn\n",
        "\n",
        "VD Padding = 1\n",
        "\n",
        "![alt text](https://miro.medium.com/max/666/1*noYcUAa_P8nRilg3Lt_nuA.png)\n",
        "\n",
        "- Stride : là bước nhảy để dịch chuyển cửa sổ Kernel\n",
        "\n",
        "- Sau khi tính toán xong ta sẽ sử dụng 1 số hàm activation như Relu, sigmod để loại bỏ đi 1 số chi tiết thừa.\n",
        "\n",
        "Mục đích khi dùng Convolution : Có nhiều mục đích nhưng chung quy lại cũng là khai phá các đặc tính của ảnh phục vụ cho việc nhận diện và lý do tại sao lại dùng Convolution vì tích chập nó khá dễ tính nên ta sử dụng\n",
        "\n",
        "II) Pooling:\n",
        "  - sau lớp phân tích ảnh lấy đặc trưng thì ta cũng không thể cho toàn bộ lượng data đó vào trực tiếp để nhận diện luôn được vì số lượng tham số quá lớn do đó ta cần giải pháp để giảm thiểu số lượng tham số nhưng vẫn giữ được những thứ cốt lõi của bức ảnh.\n",
        "  - Pooling chính là phương pháp co nhỏ ảnh nhưng vẫn có thể giữ được những thứ đặc trưng nhất của bức ảnh.\n",
        "  Có 2 Loại thường thấy đó là MaxPooling và AveragePooling :\n",
        "\n",
        "  MaxPooling :\n",
        "  \n",
        "  \n",
        "  ![alt text](https://www.machinecurve.com/wp-content/uploads/2020/01/Max-Pooling-2.png)\n",
        "\n",
        "  AveragePooling :\n",
        "\n",
        "  ![alt text](https://www.machinecurve.com/wp-content/uploads/2020/01/Average-Pooling-1.png)\n",
        "\n",
        "Sau khi đưa qua các lớp Convolution và Pooling thì cuối cùng sẽ là các lớp Fully Connected , tức là đưa nó qua các layer hình thành DNN để làm bài toán phân loại.\n",
        "\n",
        "Ta có mô hình :\n",
        "\n",
        "![alt text](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/Images/ConvnetDiagram.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TRANSFER LEARNING:\n",
        "\n",
        "- Đây là 1 kĩ thuật được sử dụng trong machine learning khi mà ta sử dụng lại 1 model đã được train từ trước khi thực hiện tác vụ 1 cho tác vụ thứ 2 với điều kiện 2 tác vụ này phải cùng liên quan đến nhau( Vd cùng nhận diện con người, thú, xe hơi...)\n",
        "- Transfer Learning cũng được xem là 1 phương pháp tối ưu để tăng tốc quá trình xử lý và cải thiện độ chính xác cho các tác vụ phía sau\n",
        "\n",
        "- Có 2 loại Transfer Learning đó là:\n",
        "\n",
        "I) Feature Extractor:\n",
        "- chúng ta có thể sử dụng Feature Extractor đã được train từ các model trước để trích xuất các features cho model của chúng ta thay vì phải tạo ra một Feature Extractor mới và train lại từ đầu. VD trong mô hình CNN thì ta lấy phần ConvNet của các model trước cho vào ConvNet của model mới và sử dụng nó như input để dùng FCs thực hiện phân loại ảnh.\n",
        "- Giữ lại toàn bộ phần feature extractor của pre-trained model ( coi như là ăn xổi luôn ) còn bỏ đi tất cả phần FC \n",
        "\n",
        "![alt text](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/featureExtractor.png?w=666&ssl=1)\n",
        "\n",
        "II) Fine-Tuning:\n",
        "- cũng là việc sử dụng lại Feature Extractor trước nhưng nó có thể bỏ đi 1 số layer hoặc giữ nguyên( tùy thuộc và mức độ giống nhau của data) của pretrained model và thêm 1 số layer Convolution và FCs cần thiết để tạo thành model mới. Việc tinh chỉnh ở đây chính là việc tinh chỉnh lại các weight trong model cũ.\n",
        "- Việc tinh chỉnh này phụ thuộc vào dữ liệu và các Layer mới thêm vào, ta có thể tinh chỉnh weight của toàn bộ model hoặc chỉ 1 số layer cần thiết (còn việc nhận biết Layer nào cần thiết thì em chưa tìm hiểu) phụ thuộc vào tg và dữ iệu đang có, còn nhưng layer còn lại không train thì ta gọi là freeze tức là W của layer đó là áp nguyên W của pre-trained model.\n",
        "- Thông thường sẽ không học các giá trị weight ở các layer đầu (do mấy layer đầu thường là biểu diễn dữ liệu ở dạng low-level vision - thị giác máy cấp thấp, chứa thông tin cơ bản của ảnh như cạnh, texture) còn layer cuối thường chứa thông tin ở cấp cao, liên quan tới ứng dụng, task cụ thể. Tuy nhiên tùy mối tương quan của hai task (source và target task) và thiết lập learning rate tương ứng.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "III ) Khi nào nên sử dụng Transfer Learning :\n",
        "- Khi muốn có model với khởi tạo weight ban đầu tốt hơn\n",
        "- Khi ta không có đủ dữ liệu để train tạo nên 1 model mà có chức năng tương tự với các pre-trained model.\n",
        "- Tùy thuộc vào dữ liệu ta có để có thể áp dụng từng cách để train model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pXYFOo0XpAI",
        "colab_type": "text"
      },
      "source": [
        "#AlexNet\n",
        "\n",
        "Kiến trúc :\n",
        "- Chứa 5 Convolution Layer và 3 Pooling.\n",
        "![alt text](https://cdn-images-1.medium.com/max/1024/1*jqKHgwZ8alM3K_JRYO_l4w.png)\n",
        "\n",
        "Một số đặc điểm:\n",
        "- Sử dụng Relu thay vì 1 số activation function khác nhằm tăng tốc độ tính toán.\n",
        "- Sử dụng  local response normalization để chuẩn hóa dữ liệu trước khi cho qua relu ở mỗi layer.\n",
        "- Sử dụng overlapping pooling cho việc giảm size.\n",
        "- Sử dụng Dropout để nhằm giảm thiểu overfitting.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0em6H3mBTdX",
        "colab_type": "text"
      },
      "source": [
        "# VGG16\n",
        "\n",
        "![alt text](https://miro.medium.com/max/2000/1*_vGloND6yyxFeFH5UyCDVg.png)\n",
        "Đây là 1 CNN model được chiến thắng cuộc thi ImageNet váo năm 2014\n",
        "\n",
        "Mô hình VGG vẫn áp dụng các lớp Convolution 2D với kernel size = 3x3 (có thể là 1x1) và stride = 1 và maxpooling với pool size = 2x2 để giảm kích thước ảnh.\n",
        "\n",
        "VGG có chia ra làm 2 loại phổ biến đấy là:\n",
        "- VGG16 có 16 layer trong đó có 13 layer conv và 3 layer FCs.\n",
        "- VGG19 có 19 layer trong đó có 16 layer conv và 3 layer FCs.\n",
        "\n",
        "Một số cấu hình khác của model VGG:\n",
        "\n",
        "![alt text](https://neurohive.io/wp-content/uploads/2018/11/Capture-564x570.jpg)\n",
        "\n",
        "Với phần về transfer learning phía trước chúng ta có thể sử dụng chính model VGG16 gốc thể dùng vào model mà chúng ta muốn thực hiện bằng Feature Extractor hoặc Fine tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plveYoaduziy",
        "colab_type": "code",
        "outputId": "a6543b74-1b20-4dbc-a318-19abb69534c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '/content/drive/My Drive/Colab Notebooks/data/proptit-aif-homework-1.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')\n",
        "import cv2 as cv\n",
        "import glob\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import  train_test_split\n",
        "import numpy as np\n",
        "np.random.seed(2)\n",
        "filesname = glob.glob(\"/content/final_train/final_train/*\")\n",
        "# filesname.sort()\n",
        "names = []\n",
        "print (filesname)\n",
        "for t in filesname:\n",
        "  names.append(int(t.split('/')[-1]))\n",
        "\n",
        "\n",
        "names.append(39)\n",
        "names.sort()\n",
        "\n",
        "marks = {}\n",
        "id = 0\n",
        "for name in names:\n",
        "  Str = str(name)\n",
        "  marks[Str] = id\n",
        "  id+=1\n",
        "print(marks)\n",
        "# maps = ['0', '2', '6', '10', '14', '22', '33', '34']\n",
        "train_set = []\n",
        "labels = []\n",
        "for files in filesname:\n",
        "  # print(files)\n",
        "  link = glob.glob(files + \"/*.png\")\n",
        "  print(files)\n",
        "  images = [cv.imread(img) for img in link]\n",
        "  lab = files.split('/')[-1]\n",
        "  # print(images[0])\n",
        "  # break\n",
        "  for img in images:\n",
        "      # img_gray = np.array(cv.cvtColor(img,cv.COLOR_BGR2GRAY))\n",
        "      resize = cv.resize(img,(64,64))\n",
        "      train_set.append(resize)\n",
        "      labels.append(marks[lab])\n",
        "\n",
        "train_set = np.array(train_set).reshape(-1,64,64,3)\n",
        "print(train_set.shape)\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y = to_categorical(labels, num_classes=8)\n",
        "print(y.shape)\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(train_set, y, test_size = 0.1,\n",
        "                                                  random_state=2)\n",
        "# data_train\n",
        "data_gen = ImageDataGenerator(rescale = 1.0/255,\n",
        "                              rotation_range=10,width_shift_range=0.2,\n",
        "                              height_shift_range = 0.2, zoom_range = 0.3,brightness_range = [0.2,1.3])\n",
        "data_gen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n",
            "['/content/final_train/final_train/10', '/content/final_train/final_train/6', '/content/final_train/final_train/33', '/content/final_train/final_train/14', '/content/final_train/final_train/34', '/content/final_train/final_train/22', '/content/final_train/final_train/0', '/content/final_train/final_train/2']\n",
            "{'0': 0, '2': 1, '6': 2, '10': 3, '14': 4, '22': 5, '33': 6, '34': 7, '39': 8}\n",
            "/content/final_train/final_train/10\n",
            "/content/final_train/final_train/6\n",
            "/content/final_train/final_train/33\n",
            "/content/final_train/final_train/14\n",
            "/content/final_train/final_train/34\n",
            "/content/final_train/final_train/22\n",
            "/content/final_train/final_train/0\n",
            "/content/final_train/final_train/2\n",
            "(7169, 64, 64, 3)\n",
            "(7169, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-QVFfO5XpQi",
        "colab_type": "code",
        "outputId": "04200458-c70c-411c-ceae-cbaf392edab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense,Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "# new_shape = np.array([64,64,3])\n",
        "pre_model = VGG16(include_top=False,input_shape=(64,64,3))\n",
        "\n",
        "flat1 = Flatten()(pre_model.output)\n",
        "\n",
        "hidden1 = Dense(units = 1024,activation = 'relu')(flat1)\n",
        "drop1 = Dropout(0.5)(hidden1)\n",
        "\n",
        "# hidden3 = Dense(units = 1024,activation = 'relu')(drop1)\n",
        "# drop3 = Dropout(0.5)(hidden3)\n",
        "\n",
        "# hidden2 = Dense(units = 512, activation = 'relu')(hidden1)\n",
        "# drop2 = Dropout(0.5)(hidden2)\n",
        "\n",
        "output = Dense(units = 8,activation='softmax')(drop1)\n",
        "# pre_model.summary()\n",
        "\n",
        "model = Model(inputs = pre_model.inputs, outputs = output)\n",
        "model.summary()\n",
        "# model\n",
        "# for layer in pre_model.layers[15:]:\n",
        "    # layer.trainable = True\n",
        "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')\n",
        "model.fit_generator(data_gen.flow(X_train,Y_train,batch_size=100),\n",
        "                    steps_per_epoch=X_train.shape[0]/100,\n",
        "                    epochs=40,\n",
        "                    validation_data=(X_val,Y_val)\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 8)                 8200      \n",
            "=================================================================\n",
            "Total params: 16,821,064\n",
            "Trainable params: 16,821,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "65/64 [==============================] - 10s 154ms/step - loss: 1.8275 - accuracy: 0.3362 - val_loss: 110.4821 - val_accuracy: 0.2929\n",
            "Epoch 2/40\n",
            "65/64 [==============================] - 10s 151ms/step - loss: 1.3843 - accuracy: 0.4668 - val_loss: 36.6010 - val_accuracy: 0.2050\n",
            "Epoch 3/40\n",
            "65/64 [==============================] - 10s 151ms/step - loss: 0.8072 - accuracy: 0.7111 - val_loss: 25.8823 - val_accuracy: 0.1576\n",
            "Epoch 4/40\n",
            "65/64 [==============================] - 10s 150ms/step - loss: 0.4446 - accuracy: 0.8537 - val_loss: 17.3776 - val_accuracy: 0.4073\n",
            "Epoch 5/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.2555 - accuracy: 0.9293 - val_loss: 10.2211 - val_accuracy: 0.5551\n",
            "Epoch 6/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.2496 - accuracy: 0.9312 - val_loss: 5.7239 - val_accuracy: 0.7350\n",
            "Epoch 7/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.1355 - accuracy: 0.9566 - val_loss: 6.5010 - val_accuracy: 0.7601\n",
            "Epoch 8/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.0808 - accuracy: 0.9781 - val_loss: 7.2818 - val_accuracy: 0.6778\n",
            "Epoch 9/40\n",
            "65/64 [==============================] - 10s 151ms/step - loss: 0.2468 - accuracy: 0.9357 - val_loss: 11.9495 - val_accuracy: 0.4533\n",
            "Epoch 10/40\n",
            "65/64 [==============================] - 10s 151ms/step - loss: 0.1687 - accuracy: 0.9524 - val_loss: 11.5524 - val_accuracy: 0.8605\n",
            "Epoch 11/40\n",
            "65/64 [==============================] - 10s 151ms/step - loss: 0.0953 - accuracy: 0.9732 - val_loss: 2.3289 - val_accuracy: 0.9777\n",
            "Epoch 12/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 2.9562 - accuracy: 0.5330 - val_loss: 23.0193 - val_accuracy: 0.2929\n",
            "Epoch 13/40\n",
            "65/64 [==============================] - 10s 153ms/step - loss: 1.6965 - accuracy: 0.3286 - val_loss: 62.6015 - val_accuracy: 0.1060\n",
            "Epoch 14/40\n",
            "65/64 [==============================] - 10s 154ms/step - loss: 1.3280 - accuracy: 0.4603 - val_loss: 42.4640 - val_accuracy: 0.2008\n",
            "Epoch 15/40\n",
            "65/64 [==============================] - 10s 158ms/step - loss: 0.8873 - accuracy: 0.6519 - val_loss: 32.7376 - val_accuracy: 0.2831\n",
            "Epoch 16/40\n",
            "65/64 [==============================] - 10s 158ms/step - loss: 0.6359 - accuracy: 0.7633 - val_loss: 45.2172 - val_accuracy: 0.2580\n",
            "Epoch 17/40\n",
            "65/64 [==============================] - 10s 154ms/step - loss: 0.4378 - accuracy: 0.8377 - val_loss: 25.7943 - val_accuracy: 0.4965\n",
            "Epoch 18/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.3499 - accuracy: 0.8852 - val_loss: 15.4454 - val_accuracy: 0.6095\n",
            "Epoch 19/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.2664 - accuracy: 0.9143 - val_loss: 20.9162 - val_accuracy: 0.4672\n",
            "Epoch 20/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.2312 - accuracy: 0.9250 - val_loss: 46.8221 - val_accuracy: 0.4840\n",
            "Epoch 21/40\n",
            "65/64 [==============================] - 10s 152ms/step - loss: 0.1743 - accuracy: 0.9456 - val_loss: 34.4308 - val_accuracy: 0.4630\n",
            "Epoch 22/40\n",
            "65/64 [==============================] - 10s 156ms/step - loss: 0.1652 - accuracy: 0.9461 - val_loss: 18.2319 - val_accuracy: 0.6039\n",
            "Epoch 23/40\n",
            "65/64 [==============================] - 10s 157ms/step - loss: 0.1665 - accuracy: 0.9487 - val_loss: 34.6821 - val_accuracy: 0.5607\n",
            "Epoch 24/40\n",
            " 6/64 [=>............................] - ETA: 7s - loss: 0.1945 - accuracy: 0.9533"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RloQf7iGuy1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2CXjuHK2iJJ",
        "colab_type": "text"
      },
      "source": [
        "Có thể thấy code trên đã bị overfitting nên có thể thấy rằng áp dụng nguyên các weight của pre_train sẽ dễ bị overfitting nếu dữ liệu của chúng ta tương đối nhỏ với dữ liệu của pre-trained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z_0EPy7eOXr",
        "colab_type": "text"
      },
      "source": [
        "#R-CNN ( Region CNN )\n",
        "\n",
        "Với CNN ta có thể giải quyết bài toán phân loại ảnh, nhưng trong thực tế rất ít ảnh chỉ có 1 chủ thể như vậy đa phần là 1 bức ảnh chứa nhiều chủ thể nhưng CNN lại chỉ nhận biết từng chủ thể nhất định. Do đó ta có bài toán object dettection nhằm phân loại các vật thể có thể có trong bức anh thông qua việc sử dụng CNN.\n",
        "\n"
      ]
    }
  ]
}