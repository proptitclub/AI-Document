{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOF0EO9sbYacw78bWbGGTeN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoaileba/AI/blob/master/VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DglmAxX3VaiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1E3yYIAVZol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e5wLVHuVdXt",
        "colab_type": "text"
      },
      "source": [
        "# VGG\n",
        "\n",
        "Là 1 kiến trúc của mạng CNN được phát triển sau AlexNet nhưng deeper và đem lại kết quả khá cao trong nhận dang. VGG được phát triển có nhiểu biens thể nhưng được biết nhiều nhất là model có 16 layer và 19 layer hay thường đc biết là VGG16 và VGG19\n",
        "\n",
        "I)Mô Hình VGG:\n",
        "\n",
        "- Mô Hình VGG có rất nhiều phiên bản khác nhau mọi người có thể tham khảo ở hình ảnh bên dưới :\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1400/1*lZTWFT36PXsZZK3HjZ3jFQ.png)\n",
        "\n",
        "\n",
        "- Có thể thây vẫn như AlexNet thì VGG vẫn sử dụng các lớp Convolution và Maxpooling để có thể lấy ra đặc tính của ảnh. Nhưng nó được gọi là sâu hơn so với AlexNet là vì số lượng lớp convolution tăng lên gấp đôi và số lượng các filter từng lớp tăng lên đáng kể so với AlexNet điều này cho phép VGG có khả năng học sâu hơn \n",
        "\n",
        "- Khác với AlexNet Khi mô hình này sử dụng các filter có kích thước tương đối lớn nên dễ bỏ qua chi tiết cuat bức ảnh. VGG sử dụng filter nhỏ hơn rất nhiều là 3x3 thay cho 11x11 hay 7x7 vậy tại sao lại sử dụng 3x3 thay vì 11x11 ?\n",
        "\n",
        "  - Hãy làm 1 phép tính với 3 filter 11x11 thì lượng tham số là 11x11x3 = 363\n",
        "\n",
        "  - Trong khi đó hãy thử với 3 filter 3x3 thì lượng tham số lúc này chỉ có 3x3x3 = 27 thấp hơn rất rất nhiều so với filter của 11x11 với cùng số lượng filter\n",
        "Hãy nhìn bảng sau để có thể thấy sự chênh lệch ấy:\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-87c39f7ffcaecf9f5470111d29f7ce6a.webp)\n",
        "\n",
        "với những filter nhỏ như vậy thứ nhất ta sẽ tính toán các chi tiết của ảnh tốt hơn và với lượng tham số giảm đi ta có thể tăng độ sâu của mô hình lên nhiều hơn.\n",
        "\n",
        "- Tuy nhiên đối với các mô hình với VGG16 thì lượng tham số vẫn rất nhiều gấp đối so với AlexNet nhưng vì sử dụng filter kích thước nhỏ hơn nên độ chi tiết bức ảnh sẽ được học chi tiết hơn. Nhưng quá nhiều tham số thì lượng\n",
        "thông tin phải lưu trữ trở nên rất lớn \n",
        "\n",
        "    - VGG16 - 528 MB - 138,357,544 tham số\n",
        "\n",
        "    - VGG19 - 549 MB - 143,667,240 tham số\n",
        "\n",
        "- Ngoài những điều kể ở trên thì các hàm activation của 2 mô hình VGG và AlexNet đều tương đối giống nhau\n",
        "II) Over fiting :\n",
        "- Cũng giống như AlexNet thì VGG cũng sử dụng Data Augmentation để tăng cường dũ liệu để giúp VGG nhìn bức ảnh với nhiều khía cạnh khác nhau.\n",
        "- sử Dụng Dropout để giảm thiểu overfiting\n"
      ]
    }
  ]
}